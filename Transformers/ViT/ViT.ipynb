{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AQ24W9Lf_p-s"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shahj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "7xKe_1qeacf-",
        "outputId": "eabb0aca-55b7-4cb6-9a6c-902d105012dc"
      },
      "outputs": [],
      "source": [
        "# Define the number of patches and the patch size\n",
        "num_patches = 196  # 14 x 14 patches for a 224 x 224 image\n",
        "patch_size = 16    # 16 x 16 pixels for each patch\n",
        "num_channels = 3   # 3 channels for RGB images\n",
        "\n",
        "# Define the train and val transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1, patch_size * patch_size * num_channels)),\n",
        "])\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1, patch_size * patch_size * num_channels)),\n",
        "])\n",
        "\n",
        "# Load the Tiny ImageNet dataset\n",
        "train_dataset = ImageFolder('timn/train', transform=train_transforms)\n",
        "val_dataset = ImageFolder('timn/val', transform=val_transforms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8PwtT1k1WD04"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create data loaders for training and validation data\n",
        "# Define the train and val loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i,j in train_loader:\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4bo6pUoZ2Rwr"
      },
      "outputs": [],
      "source": [
        "class ClassToken():\n",
        "  def __init__(self,batch_size,dim):\n",
        "    self.token = np.random.normal(scale=0.1, size=(batch_size,1, dim))\n",
        "  \n",
        "  def prepend(self,words):\n",
        "    print(\"X shape is : \",words.shape)\n",
        "    print(\"Token shape is : \",self.token.shape)\n",
        "    return np.concatenate((self.token,words),axis=1) # [batch_size,196,768]+[batch_size,1,768]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oEHa-l0qAl_V"
      },
      "outputs": [],
      "source": [
        "def softmax(X,axis):\n",
        "  exp_X = np.exp(X)\n",
        "  return exp_X/np.sum(exp_X,axis=axis,keepdims=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UjRlTahXgjHU"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def attention(self,q,k,v):\n",
        "    dk = len(q[0])\n",
        "    attn= np.matmul(softmax(np.matmul(q,np.swapaxes(k, -1, -2))/np.sqrt(dk),axis=-1),v) # (1,dk) x (dk,1) x (1,dv) = (1,1) x (1,dv) = (1,dv)\n",
        "    print(\"Attention shape : \",attn.shape)\n",
        "    return attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "iKRpxvERczvm"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention():\n",
        "  def __init__(self,dmodel,h):\n",
        "    self.h=h\n",
        "    self.dk = dmodel//h \n",
        "    self.dv = dmodel//h\n",
        "    self.WQ = []\n",
        "    self.WK = []\n",
        "    self.WV = []\n",
        "    self.WO = np.random.normal(scale=0.1, size=(h*self.dv, dmodel))\n",
        "    self.sdpa = ScaledDotProductAttention()\n",
        "    self.WQ = np.random.normal(scale=0.1, size=(h,dmodel, self.dk))\n",
        "    self.WK = np.random.normal(scale=0.1, size=(h,dmodel, self.dk))\n",
        "    self.WV = np.random.normal(scale=0.1, size=(h,dmodel, self.dv))\n",
        "    self.WQ = np.array(self.WQ)\n",
        "    self.WK = np.array(self.WK)\n",
        "    self.WV = np.array(self.WV)\n",
        "    print(\"WQ shape : \",self.WQ.shape)\n",
        "    pass\n",
        "\n",
        "  def MultiHead(self,Q,K,V):\n",
        "    head = []\n",
        "    q = np.matmul(Q,self.WQ) # (1,197,768) * (8,768,768/8) -> (8,197,768/8)\n",
        "    print(\"Query shape : \",q.shape)\n",
        "    k = np.matmul(K,self.WK)\n",
        "    v = np.matmul(V,self.WV)\n",
        "    head= self.sdpa.attention(q,k,v)\n",
        "    head = np.concatenate(head,axis=1)\n",
        "    print(\"Head shape : \",head.shape)\n",
        "    multihead = np.dot(head,self.WO) # (dmodel,dv*h)\n",
        "    print(\"Multi-Head Shape : \",multihead.shape)\n",
        "    return multihead\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ua_bX8Pvc6HW"
      },
      "outputs": [],
      "source": [
        "class AddAndNorm():\n",
        "  def __init__(self,feat_size):\n",
        "    self.epsilon = 1e-8\n",
        "    self.gamma = np.ones(feat_size)\n",
        "    self.beta = np.zeros(feat_size)\n",
        "  def add(self,x,y):\n",
        "    return x+y\n",
        "  def norm(self,x):\n",
        "    #print(\"Norming\")\n",
        "    return np.multiply(self.gamma,(x-np.mean(x))) / np.sqrt(np.var(x)+self.epsilon)+self.beta\n",
        "\n",
        "class Norm():\n",
        "  def __init__(self,feat_size):\n",
        "    self.epsilon = 1e-8\n",
        "    self.gamma = np.ones(feat_size)\n",
        "    self.beta = np.zeros(feat_size)\n",
        "  def norm(self,x):\n",
        "    #print(\"Norming\")\n",
        "    return np.multiply(self.gamma,(x-np.mean(x))) / np.sqrt(np.var(x)+self.epsilon)+self.beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HLbWuRUxc_g2"
      },
      "outputs": [],
      "source": [
        "\n",
        "import math\n",
        "class FeedForward():\n",
        "  def __init__(self,in_dim,out_dim):\n",
        "    self.out_dim = out_dim\n",
        "    self.W = np.random.normal(scale=np.sqrt(2.0 / in_dim), size=(in_dim, out_dim))\n",
        "    self.b = np.zeros((out_dim,)) \n",
        "\n",
        "  def forward(self,X):\n",
        "    return np.dot(X,self.W)+self.b\n",
        "  \n",
        "class MLP():\n",
        "  def __init__(self,d_model,d_ff,activation):\n",
        "    self.d_ff=d_ff\n",
        "    self.ff1 = FeedForward(d_model,d_ff)\n",
        "    self.ff2 = FeedForward(d_ff,d_model)\n",
        "    if activation == \"GELU\":\n",
        "      self.activation = self.GELU\n",
        "    elif activation == \"RELU\":\n",
        "      self.activation = self.RELU\n",
        "\n",
        "  def RELU(self,x):\n",
        "    return np.maximum(x,0)\n",
        "  \n",
        "  def GELU(self,x):\n",
        "    # return 0.5 * x * (1+self.erf(x/np.sqrt(2)))\n",
        "    return 0.5 * x * (1+np.vectorize(math.erf)(x/np.sqrt(2)))\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.GELU(self.ff2.forward(self.GELU(self.ff1.forward(x))))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "def CrossEntropyLoss(y_pred,y_true):\n",
        "    n = len(y_pred[-1])\n",
        "    return -np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
        "    # return (-1/n) * (np.dot(y_true,np.log(y_pred).T) + np.dot(1-y_true,np.log(1-y_pred).T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "wGev7DpidFkV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "196\n",
            "WQ shape :  (12, 768, 64)\n"
          ]
        }
      ],
      "source": [
        "class Encoder():\n",
        "  def __init__(self,batch_size=1,vocab_size=196,dmodel=768,h=12,d_ff=3072,num_classes = 200):\n",
        "    # self.ie = InputEmbedding(vocab_size,dmodel)\n",
        "    self.mha = MultiHeadAttention(dmodel,h)\n",
        "    self.ffn = MLP(d_ff=d_ff,d_model=dmodel,activation='GELU')\n",
        "    self.an = AddAndNorm((1,dmodel))\n",
        "    self.cls = ClassToken(batch_size=batch_size,dim=dmodel)\n",
        "    self.num_classes = num_classes\n",
        "    self.batch_size = batch_size\n",
        "  def encode(self,X):\n",
        "    X = self.cls.prepend(X)\n",
        "    print(\"Prepended Class Token, Shape: \",X.shape)\n",
        "    X = self.an.norm(X)\n",
        "    multi_head_op = self.mha.MultiHead(X,X,X)\n",
        "    print(\"Performed Multi-Headed Attention\")\n",
        "    print(\"Multi Head OP shape : \",multi_head_op.shape),\n",
        "    mhan=self.an.norm(self.an.add(X,multi_head_op))\n",
        "    ffn_op = self.ffn.forward(mhan)\n",
        "    print(\"Passed through Feed-Forward Layer\")\n",
        "    op =self.an.add(mhan,ffn_op)\n",
        "    return op \n",
        "  \n",
        "  def loss(self,y_true):\n",
        "    one_hot_encoded = np.zeros((self.batch_size,self.num_classes))\n",
        "    one_hot_encoded[np.arange(self.batch_size),y_true]=1 #set the value at index [i, y_true[i]]\n",
        "    return CrossEntropyLoss(self.class_prob,one_hot_encoded)\n",
        "\n",
        "\n",
        "  def pred(self,input):\n",
        "    encoded = self.encode(input)\n",
        "    X = encoded[:,0,:]\n",
        "    classification_head = FeedForward(in_dim = X.shape[-1],out_dim =self.num_classes ) # 200 output classes\n",
        "    self.logits = classification_head.forward(X)\n",
        "    self.class_prob = softmax(self.logits, axis=-1)\n",
        "    # print(\"Logits Shape : \",self.logits.shape) #Just because dimension of op matches doesn't mean it's right, axis = 0 would also give op (1,200) but it's not right, correct is axis = 1 i.e., last axis=-1.\n",
        "    # print(\"Len Logits.shape - 1 is \",len(logits.shape)-1) #Not len(logits)-1\n",
        "    # print(\"Class Prob Shape : \",class_prob.shape)\n",
        "    y = np.argmax(self.class_prob,axis=-1)\n",
        "    return y\n",
        "\n",
        "vocab_size = 224*224 // (16*16)\n",
        "print(vocab_size)\n",
        "encoder = Encoder(vocab_size=vocab_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 196, 768])\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "\n",
        "# Get the first image from the train loader\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "# Print the shape of the image tensor\n",
        "print(images.shape)\n",
        "input = images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 196, 768)\n"
          ]
        }
      ],
      "source": [
        "print(images.numpy().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[32]\n"
          ]
        }
      ],
      "source": [
        "print(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oibncyAiBawE",
        "outputId": "a3248a7b-787b-443f-f784-0ea2e0ab6dee"
      },
      "outputs": [],
      "source": [
        "# encoder_op = encoder.encode(images.numpy())\n",
        "# print(encoder_op)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTmN_1FoBgcs",
        "outputId": "eed3c8b2-1c97-4639-e905-3e589b888dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 197, 768)\n"
          ]
        }
      ],
      "source": [
        "# print(encoder_op.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape is :  (1, 196, 768)\n",
            "Token shape is :  (1, 1, 768)\n",
            "Prepended Class Token, Shape:  (1, 197, 768)\n",
            "Query shape :  (12, 197, 64)\n",
            "Attention shape :  (12, 197, 64)\n",
            "Head shape :  (197, 768)\n",
            "Multi-Head Shape :  (197, 768)\n",
            "Performed Multi-Headed Attention\n",
            "Multi Head OP shape :  (197, 768)\n",
            "Passed through Feed-Forward Layer\n"
          ]
        }
      ],
      "source": [
        "pred = encoder.pred(images.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1,)\n"
          ]
        }
      ],
      "source": [
        "print(pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[112]\n"
          ]
        }
      ],
      "source": [
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[32]\n"
          ]
        }
      ],
      "source": [
        "print(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp = np.zeros(200)\n",
        "temp[10] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200,)\n",
            "(200,)\n"
          ]
        }
      ],
      "source": [
        "print(encoder.class_prob[0].shape)\n",
        "print(temp.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.05019346]]\n"
          ]
        }
      ],
      "source": [
        "loss = encoder.loss(labels.numpy())\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.83659681e-04 1.42803809e-02 1.49912716e-02 2.40114072e-05\n",
            "  9.37851953e-04 1.98097820e-02 1.14443860e-04 4.11329342e-03\n",
            "  1.32011269e-03 5.78378344e-04 1.78620641e-05 2.04686582e-04\n",
            "  2.06816249e-03 2.69366454e-04 1.40383945e-04 2.20324647e-03\n",
            "  1.60257968e-04 2.27771578e-04 2.11758221e-05 4.18921676e-05\n",
            "  6.06369287e-04 4.88965022e-05 1.58719998e-05 6.86537658e-05\n",
            "  2.71628345e-03 5.82982884e-04 1.98867334e-03 5.63010053e-03\n",
            "  1.47091511e-03 1.78469167e-02 2.40469537e-04 2.63055260e-04\n",
            "  1.03512784e-03 1.05656528e-05 5.61429776e-05 1.52178847e-04\n",
            "  1.30988687e-04 6.72176106e-05 1.78186406e-04 4.01635236e-04\n",
            "  2.42524117e-02 4.40830901e-05 1.56386539e-02 8.37649332e-02\n",
            "  8.89839113e-07 7.66777298e-04 9.37002406e-05 4.15835598e-03\n",
            "  5.35968675e-02 1.83398810e-03 6.83115516e-04 9.26473484e-05\n",
            "  1.25650070e-03 8.81574167e-03 8.41732025e-04 3.47895563e-05\n",
            "  4.91263630e-04 5.06177216e-05 3.70362476e-04 4.77722889e-04\n",
            "  8.60407460e-04 8.41741575e-04 2.71406553e-02 1.86821159e-04\n",
            "  1.45992749e-04 2.04182683e-04 5.44217900e-04 3.63981876e-05\n",
            "  5.71515104e-03 2.34822320e-05 3.35344637e-03 3.66413681e-05\n",
            "  2.73833512e-04 2.92528039e-03 5.87549600e-03 4.92485517e-04\n",
            "  7.26153819e-04 3.25082484e-04 8.51201718e-03 1.03597602e-04\n",
            "  1.57917888e-03 4.31017402e-03 7.50135076e-05 8.57703217e-04\n",
            "  3.65208468e-04 1.59165822e-03 2.56720665e-03 5.81188190e-05\n",
            "  9.59934023e-05 1.50798944e-02 2.75554915e-04 1.09216166e-05\n",
            "  5.93897763e-05 1.28016912e-04 4.24413782e-04 5.40039483e-02\n",
            "  1.43658203e-04 6.11732376e-03 2.98169512e-04 1.57859410e-05\n",
            "  4.67978080e-03 7.14243764e-04 5.87547028e-04 3.47698851e-04\n",
            "  4.92998944e-05 1.33551780e-04 8.84333802e-04 1.90175981e-04\n",
            "  2.69195835e-03 9.06749167e-05 2.55245849e-04 2.03415327e-05\n",
            "  3.14061891e-01 1.31723836e-03 8.89087716e-05 4.29834525e-04\n",
            "  1.15621347e-04 1.55768287e-02 4.84541572e-03 8.20402991e-04\n",
            "  1.79645055e-04 6.90844066e-03 3.69675400e-04 3.86198979e-04\n",
            "  1.83265898e-03 1.14216057e-03 5.98950021e-04 4.57450845e-05\n",
            "  3.02612053e-04 5.51032256e-04 2.74873634e-04 2.32339560e-04\n",
            "  9.11385552e-05 1.84546043e-03 5.97508814e-05 1.32200397e-03\n",
            "  1.45655518e-04 5.09342221e-04 1.10955264e-04 3.28499602e-02\n",
            "  7.79301159e-03 1.01905707e-03 2.15039949e-02 1.12808085e-06\n",
            "  1.71134617e-04 9.14403096e-04 2.29566606e-03 9.99975211e-03\n",
            "  6.08657484e-04 1.28262132e-02 1.53021250e-03 1.56567547e-04\n",
            "  4.60657208e-05 1.38021097e-05 3.86413819e-05 1.80673612e-04\n",
            "  1.18968405e-03 2.50889966e-03 1.24179845e-03 1.00682939e-02\n",
            "  1.78286974e-04 7.41355610e-05 1.12940532e-03 2.27815151e-04\n",
            "  3.50165414e-03 1.30288082e-04 6.96728077e-05 6.09308437e-05\n",
            "  2.84702169e-04 1.48446972e-04 2.04949835e-03 1.13490390e-03\n",
            "  1.22935483e-03 1.55918610e-05 1.06794803e-04 1.51165252e-03\n",
            "  1.38246426e-03 8.40303828e-05 9.88675268e-05 9.28312443e-03\n",
            "  8.23262921e-03 1.23058667e-03 2.18599860e-03 1.24819360e-03\n",
            "  8.68714249e-05 2.88951741e-02 7.40615143e-04 4.03551022e-03\n",
            "  1.16834837e-03 6.27432768e-05 7.28373104e-04 8.71647229e-05\n",
            "  1.34319216e-04 1.69431749e-03 2.70552931e-04 2.12950682e-03\n",
            "  1.00792336e-02 6.52052804e-04 5.09458405e-05 2.95319680e-03]]\n"
          ]
        }
      ],
      "source": [
        "print(encoder.class_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def normalizer(dataset):\n",
        "#     mean = np.zeros(3)\n",
        "#     std = np.zeros(3)\n",
        "#     for images,_ in dataset:\n",
        "#         print(np.mean(images.numpy(),axis=(0,1))\n",
        "#         mean+= np.mean(images.numpy(),axis=(0,1))\n",
        "#         std += np.std(images.numpy(),axis=(0,1))\n",
        "#     mean /= len(dataset)\n",
        "#     std /= len(dataset)\n",
        "\n",
        "#     normalized_dataset = transforms.Normalize(mean=mean,std=std)(dataset)\n",
        "#     return normalized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_dataset = normalizer(train_dataset)\n",
        "# val_dataset = normalizer(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from scipy.integrate import quadrature\n",
        "# def f(self,t):\n",
        "  #   return np.exp(-t**2)\n",
        "\n",
        "  # def MonteCarlo(self,x,a,b):\n",
        "  #   N=10000\n",
        "  #   sample = np.random.uniform(a,b,N)\n",
        "  #   y = self.f(sample)\n",
        "  #   I = (b-a)*np.mean(y)\n",
        "  #   return I\n",
        "\n",
        "  # def gaussian_quadrature(self,x):\n",
        "  #   return quadrature(self.f,0,x)\n",
        "  \n",
        "  # def erf(self,x):\n",
        "  #   I,_ = np.vectorize(self.gaussian_quadrature)(x)\n",
        "  #   # I = self.MonteCarlo(0,x)\n",
        "  #   return (2*np.pi)* (I)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
