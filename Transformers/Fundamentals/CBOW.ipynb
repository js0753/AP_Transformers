{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch87YAjXQS3i",
        "outputId": "e1da696c-d222-4190-cba7-d3f8c65e9740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk \n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown \n",
        "from scipy.sparse import csr_matrix\n",
        "import scipy.sparse as sp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4R6geApQS3k",
        "outputId": "9bc346e4-37da-494a-e4e8-3fa5616024b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n"
          ]
        }
      ],
      "source": [
        "corpus = brown.sents()\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YYB1d3P3QS3k"
      },
      "outputs": [],
      "source": [
        "processed_corpus = [[word.lower() for word in sent] for sent in corpus]\n",
        "#print(processed_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wgFM1qGsQS3k"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "word_dic = {}\n",
        "word_vec_dim = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Dn5SpxNjQS3l"
      },
      "outputs": [],
      "source": [
        "# def getRandomGaussian(u,sd,x):\n",
        "#     return (math.e**((((x-u)/sd)**2)/2))/(sd*math.sqrt(2*math.pi))  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HkNYjcPkQS3l"
      },
      "outputs": [],
      "source": [
        "word_id =0\n",
        "for sent in processed_corpus:\n",
        "    for word in sent:\n",
        "        if word in word_dic: continue\n",
        "        word_dic[word] = word_id\n",
        "        word_id +=1\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aa1-4FZfQS3l"
      },
      "outputs": [],
      "source": [
        "vocabulary_size = len(word_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4dhPW7XLQS3l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "u = 0\n",
        "sd = 1/math.sqrt(word_vec_dim)\n",
        "word_embeddings = u + sd*np.random.randn(len(word_dic),word_vec_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h80QudbQS3m",
        "outputId": "5a55f26b-7c40-4712-9273-98d7da97de03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.08030225 -0.0057572   0.14385938 ... -0.0753959  -0.06330271\n",
            "   0.00990981]\n",
            " [ 0.18305358 -0.00496262 -0.07639269 ...  0.06876746  0.06896138\n",
            "  -0.06739364]\n",
            " [-0.06895263  0.02385585 -0.24705506 ...  0.13721291 -0.14078552\n",
            "  -0.0439171 ]\n",
            " ...\n",
            " [-0.04101387  0.01836216 -0.17088447 ...  0.06655138 -0.0724738\n",
            "  -0.02759786]\n",
            " [-0.16883073 -0.08946449 -0.12061808 ...  0.02054797 -0.01287911\n",
            "  -0.0367249 ]\n",
            " [-0.12073965 -0.03547467  0.0042613  ...  0.04763543 -0.08877104\n",
            "   0.12302579]]\n"
          ]
        }
      ],
      "source": [
        "print(word_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2 = u + sd*np.random.randn(word_vec_dim,len(word_dic))"
      ],
      "metadata": {
        "id": "Z8hc2PNYEZS7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aksn1BgCFlhk",
        "outputId": "4c89addf-f4e0-4c7f-84a6-6e6e691504f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 49815)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Thanks ChatGPT\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "def gen_data_set(corpus, window, word_dic):\n",
        "    X = []\n",
        "    y = []\n",
        "    vocabulary_size = len(word_dic)\n",
        "    row = []\n",
        "    col = []\n",
        "    data = []\n",
        "    for sent in corpus:\n",
        "        for tw_index in range(len(sent)):\n",
        "            target_word = sent[tw_index]\n",
        "            context = sent[max(0, tw_index - window):tw_index] + sent[tw_index + 1:min(len(sent), tw_index + window + 1)]\n",
        "            for cw_index in range(len(context)):\n",
        "                context_word = context[cw_index]\n",
        "                row.append(tw_index)\n",
        "                col.append(word_dic[context_word])\n",
        "                data.append(1)\n",
        "    X = csr_matrix((data, (row, col)), shape=(len(corpus), vocabulary_size))\n",
        "    y = [word_dic[word] for sent in corpus for word in sent]\n",
        "    return X, y\n",
        "\n"
      ],
      "metadata": {
        "id": "wW3XY6Dq3o2M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import jit, cuda"
      ],
      "metadata": {
        "id": "suERsbHdQmSe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "X7x9jsejQS3m"
      },
      "outputs": [],
      "source": [
        "# window = 5\n",
        "# def gen_data_set(corpus,window,word_dic):\n",
        "#   X = []\n",
        "#   y = []\n",
        "#   vocabulary_size = len(word_dic)\n",
        "#   for sent in corpus:\n",
        "#       for tw_index in range(len(sent)):\n",
        "#           context_vec = [0 for i in range(vocabulary_size)]\n",
        "#           target_word = sent[tw_index]\n",
        "#           context = sent[max(0,tw_index-window):tw_index] + sent[tw_index+1:min(len(sent),tw_index+window+1)]\n",
        "#           for cw_index in range(max(0,tw_index-window),tw_index):\n",
        "#               context_word = sent[cw_index]\n",
        "#               context_vec[word_dic[context_word]] += 1\n",
        "#           X.append(context_vec)\n",
        "#           y.append(word_dic[target_word])\n",
        "#           #print(context)\n",
        "#           #break\n",
        "#   return X,y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window = 5"
      ],
      "metadata": {
        "id": "AdIurBkk0m-I"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "thVXn0OMQS3m"
      },
      "outputs": [],
      "source": [
        "X,y = gen_data_set(processed_corpus,window,word_dic)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmKNtq5S6iNB",
        "outputId": "f600f9cf-8287-40a0-a401-2ca7d489895d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49815, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5fI6QTD5E_e",
        "outputId": "043e6c5b-b6e8-44be-d2a9-8386c97ce732"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57340, 49815)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocabulary_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtpheUfU5Hwt",
        "outputId": "e37f437f-794c-4719-a20c-b24877d769d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "xjP0uO5f51DH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie9TgGhM5P42",
        "outputId": "ff4669f0-07d9-4d27-9883-0ad24d46702e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1161192,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    def __init__(self,weights,activation):\n",
        "      self.weights = weights\n",
        "      self.activation = activation\n",
        "      self.out = []\n",
        "\n",
        "class NN:\n",
        "  def __init__(self,layers):\n",
        "    self.layers = []\n",
        "    for l in layers:\n",
        "      self.layers.append(l)\n",
        "  \n",
        "  def activation(self,name):\n",
        "    def Relu(X):\n",
        "        X=X.todense()\n",
        "        print(\"ReLU i/p shape : \", X.shape)\n",
        "        return np.maximum(X,0)\n",
        "\n",
        "    def SoftMax(X):\n",
        "      #X=X.todense()\n",
        "      print(\"X shape is \",X.shape)\n",
        "      print(X)\n",
        "      denom = sum(np.exp(X))\n",
        "      print(\"Denominator is \",denom)\n",
        "      out = np.exp(X)/denom\n",
        "      print(sum(out))\n",
        "      return out\n",
        "\n",
        "    if name == \"ReLU\":\n",
        "      return Relu\n",
        "    elif name == \"SoftMax\":\n",
        "      return SoftMax\n",
        "    \n",
        "      \n",
        "  def ac_grad(self,name):\n",
        "    def grad_Relu(x):\n",
        "      op = (1+np.sign(x))//2\n",
        "      return op\n",
        "    \n",
        "    def grad_SoftMax(X):\n",
        "      sm = self.activation('SoftMax')(X)\n",
        "      return sm*(1-sm)\n",
        "\n",
        "    if name == 'ReLU':\n",
        "      return grad_Relu\n",
        "\n",
        "  def loss(self,name):\n",
        "    def bce(y,prob_y):\n",
        "      epsilon = 1e-10\n",
        "      prob_y = np.clip(prob_y, epsilon, 1 - epsilon)\n",
        "      N = len(y)\n",
        "      # summation = 0\n",
        "      # for i in range(len(y)):\n",
        "      #   summation+= (y[i]*np.log(prob_y[i]) + (1-y[i])*np.log(1-prob_y[i]))\n",
        "      H = (-1/N)*np.sum(y*np.log(prob_y) + (1-y)*np.log(1-prob_y))\n",
        "      return H\n",
        "    if name == 'BinaryCrossEntropy':\n",
        "      return bce\n",
        "  \n",
        "  def grad(loss):\n",
        "    def bce(y,prob_y):\n",
        "      epsilon = 1e-10\n",
        "      prob_y = np.clip(prob_y, epsilon, 1 - epsilon)\n",
        "      return y/prob_y - (1-y)/(1-prob_y)\n",
        "    if loss == 'BinaryCrossEntropy':\n",
        "      return bce\n",
        "\n",
        "  def forward(self,X):\n",
        "    #from scipy.sparse import csr_matrix\n",
        "\n",
        "    \n",
        "    print(\"Forward step\")\n",
        "    print(\"Weights shape \",self.layers[0].weights.shape)\n",
        "    print(\"Input Shape \",X.shape)\n",
        "    # Convert the weight matrix to a sparse CSR matrix\n",
        "    weights_sparse = csr_matrix(self.layers[0].weights)\n",
        "\n",
        "    # Perform the sparse matrix multiplication\n",
        "    print(self.layers[0].activation)\n",
        "    ac = self.activation(self.layers[0].activation)\n",
        "    print(type(ac))\n",
        "    X=X.reshape(1,-1)\n",
        "    #print(X)\n",
        "    print(\"Input Shape \",X.shape)\n",
        "    prod= np.dot(X, weights_sparse)\n",
        "    #print(\"Product is :\",prod)\n",
        "    out0 = ac(prod)\n",
        "    #out0 = self.activation(self.layers[0].activation)(np.dot(X,self.layers[0].weights))\n",
        "    print(\"Out0 done\")\n",
        "    self.layers[0].out = out0\n",
        "    print(out0.shape)\n",
        "    #weights2_sparse = csr_matrix(self.layers[1].weights)\n",
        "    \n",
        "    out = self.activation(self.layers[1].activation)(np.dot(out0,self.layers[1].weights))\n",
        "    print(\"Out1 done\")\n",
        "    self.layers[1].out = out\n",
        "    return out\n",
        "  \n",
        "  def backward(self,X,y):\n",
        "    print(\"Backward step\")\n",
        "    L = self.loss('BinaryCrossEntropy')(y,self.layers[1].out)\n",
        "    dLdy = self.grad('BinaryCrossEntropy')(y,self.layers[1].out)\n",
        "    dydx2 = self.ac_grad(self.layers[1].activation)(np.dot(self.layers[0].out,self.layers[1].weights))\n",
        "    dLdw1 = np.dot(dLdy,np.dot(dydx2,self.layers[0].out))\n",
        "    dLdy0 = np.dot(dLdy,np.dot(dydx2,self.layers[1].weights))\n",
        "    dy0dx1 = self.ac_grad(self.layers[0].activation)(np.dot(X,self.layers[0].weights))\n",
        "    print(X.shape, dLdy0.shape, dy0dx1.shape)\n",
        "    dLdw0 = np.dot(X,np.dot(dLdy0,dy0dx1))\n",
        "    \n",
        "    return dLdw0, dLdw1, L\n",
        "  \n",
        "  def backprop(self,X,y,alpha=0.1,max_iter=1000):\n",
        "    print(\"Beginning Backprop\")\n",
        "    losses = []\n",
        "    for iter in range(max_iter):\n",
        "      for i in range(X.shape[0]):\n",
        "        row = X[i,:]\n",
        "        target = y[i]\n",
        "        self.forward(row)\n",
        "        dLdw0, dLdw1, L = self.backward(row,target)\n",
        "        self.layers[0].weights -= alpha*dLdw0\n",
        "        self.layers[1].weights -= alpha*dLdw1\n",
        "        losses.append(L)\n",
        "        del row\n",
        "        del target\n",
        "        break\n",
        "      if abs(L - losses[-1])< 1e-5: break \n",
        "    return losses\n",
        "\n"
      ],
      "metadata": {
        "id": "Am6j-4h56EvY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NN(\n",
        "    [\n",
        "        Layer(word_embeddings,'ReLU'),\n",
        "        Layer(w2,'SoftMax')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "rY4PFCE0VzAZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = nn.backprop(X,y,0.1,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "h7-JGiO7WPRA",
        "outputId": "8055341a-33a6-413c-b1b7-e02342088dce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning Backprop\n",
            "Forward step\n",
            "Weights shape  (49815, 100)\n",
            "Input Shape  (1, 49815)\n",
            "ReLU\n",
            "<class 'function'>\n",
            "Input Shape  (1, 49815)\n",
            "ReLU i/p shape :  (1, 100)\n",
            "Out0 done\n",
            "(1, 100)\n",
            "X shape is  (1, 49815)\n",
            "[[-2426.51544731  1211.42760386 -1924.78426155 ...  1987.21324539\n",
            "  -1180.75523823   626.2717777 ]]\n",
            "Denominator is  [[0.00000000e+000             inf 0.00000000e+000 ...             inf\n",
            "  0.00000000e+000 9.69119268e+271]]\n",
            "[[nan nan nan ... nan nan  1.]]\n",
            "Out1 done\n",
            "Backward step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-0ebe57d864a6>:23: RuntimeWarning: overflow encountered in exp\n",
            "  denom = sum(np.exp(X))\n",
            "<ipython-input-31-0ebe57d864a6>:25: RuntimeWarning: overflow encountered in exp\n",
            "  out = np.exp(X)/denom\n",
            "<ipython-input-31-0ebe57d864a6>:25: RuntimeWarning: invalid value encountered in true_divide\n",
            "  out = np.exp(X)/denom\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-664c16af8e30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-0ebe57d864a6>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, X, y, alpha, max_iter)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mdLdw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdLdw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdLdw0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdLdw1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-0ebe57d864a6>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Backward step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BinaryCrossEntropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mdLdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BinaryCrossEntropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdydx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mac_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-0ebe57d864a6>\u001b[0m in \u001b[0;36mbce\u001b[0;34m(y, prob_y)\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0mprob_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0;31m# summation = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0;31m# for i in range(len(y)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7aee82db6aade83206aba3bc6c722a08c168d94c580dac58d327d87ee1e900d6"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}