{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\jainshah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "#nltk.download('brown')\n",
    "from nltk.corpus import brown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "corpus = brown.sents()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = [[word.lower() for word in sent] for sent in corpus]\n",
    "#print(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "word_dic = {}\n",
    "word_vec_dim = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getRandomGaussian(u,sd,x):\n",
    "#     return (math.e**((((x-u)/sd)**2)/2))/(sd*math.sqrt(2*math.pi))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_id =0\n",
    "for sent in processed_corpus:\n",
    "    for word in sent:\n",
    "        if word in word_dic: continue\n",
    "        word_dic[word] = word_id\n",
    "        word_id +=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(word_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "u = 0\n",
    "sd = 1/math.sqrt(word_vec_dim)\n",
    "weights = u + sd*np.random.randn(len(word_dic),word_vec_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06080885  0.03871819 -0.03088617 ... -0.16443211  0.04676061\n",
      "   0.0732467 ]\n",
      " [ 0.04974237  0.07608011 -0.26736813 ... -0.19886004  0.03046741\n",
      "   0.07669509]\n",
      " [-0.04782431 -0.07681455  0.23056697 ...  0.03034827 -0.02994224\n",
      "  -0.00150033]\n",
      " ...\n",
      " [ 0.05557308  0.1254497  -0.05165959 ... -0.18183771 -0.16670191\n",
      "  -0.06163303]\n",
      " [-0.15943564 -0.01967953  0.01830868 ...  0.00066924 -0.02289221\n",
      "  -0.01195337]\n",
      " [ 0.0009701   0.11820755 -0.01253725 ...  0.06513755 -0.18104724\n",
      "   0.14959034]]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5\n",
    "X = []\n",
    "y = []\n",
    "for sent in processed_corpus:\n",
    "    for tw_index in range(len(sent)):\n",
    "        context_vec = [0 for i in range(vocabulary_size)]\n",
    "        target_word = sent[tw_index]\n",
    "        context = sent[max(0,tw_index-window):tw_index] + sent[tw_index+1:min(len(sent),tw_index+window+1)]\n",
    "        for cw_index in range(max(0,tw_index-window),tw_index):\n",
    "            context_word = sent[cw_index]\n",
    "            context_vec[word_dic[context_word]] += 1\n",
    "        X.append(context_vec)\n",
    "        y.append(word_dic[target_word])\n",
    "        #print(context)\n",
    "        #break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7aee82db6aade83206aba3bc6c722a08c168d94c580dac58d327d87ee1e900d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
